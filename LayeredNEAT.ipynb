{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1272,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import uuid\n",
    "from tqdm import trange\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_activation(inputs, activation, passthroughs):\n",
    "    return np.where(passthroughs > 0, inputs, activation(inputs))\n",
    "\n",
    "def relu(inputs):\n",
    "    return np.where(inputs>0, inputs, 0)\n",
    "\n",
    "\n",
    "class Layer():\n",
    "    def __init__(self, input_shape, output_shape, passthrough=True, activation=\"relu\", locked=False):\n",
    "        self.weights = np.zeros((input_shape, output_shape))\n",
    "        self.bias = np.zeros(output_shape)\n",
    "        self.passthrough = np.zeros(output_shape)\n",
    "        \n",
    "        if passthrough:\n",
    "            self.passthrough = np.ones(output_shape)\n",
    "            self.weights = np.eye(input_shape, output_shape)\n",
    "        self.output_shape = output_shape\n",
    "        self.input_shape = input_shape\n",
    "        self.size = self.weights.shape\n",
    "        \n",
    "        self.locked = locked\n",
    "        \n",
    "        if activation == \"relu\":\n",
    "            self.activation = relu\n",
    "        if activation == \"tanh\":\n",
    "            self.activation = tf.keras.activations.tanh\n",
    "        \n",
    "        self.id = str(uuid.uuid1())\n",
    "\n",
    "        \n",
    "    def increase_output(self, link):\n",
    "        padding = np.zeros(shape=(self.input_shape,1))\n",
    "        padding[link] = np.random.normal((1,))\n",
    "        self.weights = np.append(self.weights, padding, axis=1)\n",
    "        \n",
    "        \n",
    "        self.bias = np.append(self.bias, 0)      \n",
    "        self.passthrough = np.append(self.passthrough, 0)  \n",
    "        \n",
    "        self.output_shape += 1\n",
    "        self.size = self.weights.shape\n",
    "        \n",
    "    def increase_input(self, link=None):\n",
    "        padding = np.zeros(shape=(1,self.output_shape))\n",
    "        if link is not None:\n",
    "            padding[0][link] = np.random.normal(1)\n",
    "        \n",
    "        self.weights = np.append(self.weights, padding, axis=0)\n",
    "        \n",
    "        self.input_shape += 1\n",
    "        self.size = self.weights.shape\n",
    "        \n",
    "    def mutate_weights(self, scale=0.1):\n",
    "        randoms = np.random.normal(scale=scale, size=self.weights.shape)\n",
    "        self.weights = np.where(self.weights != 0, self.weights + randoms, self.weights)\n",
    "    \n",
    "    def decrease_input(self):\n",
    "        self.weights = np.delete(self.weights, -1, axis=0)\n",
    "        self.input_shape -= 1\n",
    "        self.size = self.weights.shape\n",
    "        \n",
    "    def change_input_size(self, size):\n",
    "        while self.input_shape != size:\n",
    "            if self.input_shape > size:\n",
    "                self.decrease_input()\n",
    "            elif self.input_shape < size:\n",
    "                self.increase_input()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return partial_activation((np.matmul(inputs, self.weights) + self.bias), self.activation, self.passthrough)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"Layer: [shape=\" + str(self.weights.shape) + \"]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1466,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network():\n",
    "    def __init__(self, input_shape):\n",
    "        self.layers = []\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "        self.age = 0\n",
    "        self.layer_counter = 0\n",
    "        #self.layers.append(Layer(input_shape, output_shape, passthrough=True, locked=True))\n",
    "        #self.layers.append(Layer(output_shape, output_shape, passthrough=True, locked=True))\n",
    "    \n",
    "    \n",
    "    def add_layer(self, size, weights=None, biases=None, activation=\"relu\", passthrough=False, locked=False):       \n",
    "        if len(self.layers) == 0:\n",
    "            self.layers.append(Layer(self.input_shape, size, locked=True))\n",
    "        else:\n",
    "            self.layers.append(Layer(self.layers[-1].output_shape, size, locked=locked))\n",
    "        \n",
    "        \n",
    "        self.output_shape = size\n",
    "        \n",
    "    def mutate_link(self):\n",
    "        index = np.random.randint(len(self.layers) - 1)\n",
    "        \n",
    "        layer = self.layers[index]\n",
    "        next_layer = self.layers[index + 1]\n",
    "        \n",
    "        link_from = np.random.randint(layer.input_shape)\n",
    "        \n",
    "        while not next_layer.locked:\n",
    "            link_to = np.random.randint(layer.output_shape + 1) #Check if doubling/another distrubution works best\n",
    "\n",
    "            if link_to >= self.output_shape:\n",
    "                layer.increase_output(link_from)\n",
    "                next_layer.increase_input()\n",
    "                \n",
    "                index += 1\n",
    "                layer = self.layers[index]\n",
    "                next_layer = self.layers[index+1]\n",
    "                link_from = layer.input_shape - 1\n",
    "            else:\n",
    "                layer.increase_output(link_from)\n",
    "                next_layer.increase_input(link=(link_to % next_layer.output_shape))          \n",
    "                return\n",
    "        \n",
    "    def mutate_node(self):\n",
    "        index = np.random.randint(1, len(self.layers))\n",
    "        \n",
    "        layer = self.layers[index]\n",
    "        \n",
    "        # Instead of adding an additional layer convert passthroughs to nodes first\n",
    "        if np.max(layer.passthrough) == 1:\n",
    "            pass_index = np.random.randint(layer.output_shape)\n",
    "            while True:\n",
    "                if layer.passthrough[pass_index] == 1:\n",
    "                    layer.passthrough[pass_index] = 0\n",
    "                    return\n",
    "                else:\n",
    "                    pass_index = (pass_index + 1) % layer.output_shape\n",
    "        \n",
    "        # If current layer does not have any passthrough nodes, add new layer\n",
    "        new_layer = Layer(layer.input_shape, layer.input_shape, passthrough=True)\n",
    "        node_index = np.random.randint(new_layer.output_shape)\n",
    "        new_layer.passthrough[node_index] = 0\n",
    "    \n",
    "        self.layers.insert(index, new_layer)\n",
    "        \n",
    "        self.layer_counter += 1\n",
    "    \n",
    "    def mutate_weights(self):\n",
    "        for layer in self.layers:\n",
    "            layer.mutate_weights()\n",
    "    \n",
    "    \n",
    "    def mutate(self, p_link=0.2, p_node=0.2, p_mutate=0.5): \n",
    "        if np.random.choice([True, False], 1, p=[p_link, 1-p_link]):\n",
    "            self.mutate_link()\n",
    "        if np.random.choice([True, False], 1, p=[p_node, 1-p_node]):\n",
    "            self.mutate_node()  \n",
    "        if np.random.choice([True, False], 1, p=[p_node, 1-p_node]):\n",
    "            self.mutate_weights()\n",
    "    \n",
    "        \n",
    "    def trim_shapes(self):\n",
    "        previous_shape = self.layers[0].output_shape\n",
    "        for layer in self.layers[1:]:\n",
    "            if layer.input_shape != previous_shape:\n",
    "                layer.change_input_size(previous_shape)\n",
    "\n",
    "            previous_shape = layer.output_shape\n",
    "        \n",
    "        \n",
    "    \n",
    "    def predict(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer.call(x)\n",
    "        return x\n",
    "    \n",
    "    def print_graph(self):\n",
    "        G = nx.Graph()\n",
    "        \n",
    "        for x in range(len(self.layers) - 1):\n",
    "            layer = self.layers[x]\n",
    "            next_layer = self.layers[x+1]\n",
    "            \n",
    "            for row_index in range(len(layer.weights)):\n",
    "                for col_index in range(len(layer.weights[0])):\n",
    "                    if layer.weights[row_index, col_index] != 0 and layer.passthrough[col_index] == 0:\n",
    "                        G.add_node(str(layer.id) + \"_\" + str(row_index), subset=layer.id)\n",
    "                        G.add_node(str(next_layer.id) + \"_\" + str(col_index), subset=next_layer.id)\n",
    "                        G.add_edge(str(layer.id) + \"_\" + str(row_index), str(next_layer.id) + \"_\" + str(col_index))\n",
    "                        \n",
    "        pos = nx.multipartite_layout(G)\n",
    "        nx.draw(G, pos=pos)\n",
    "                    \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"Network: Layers= \\n\" + str(self.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1467,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossbreed(mom, dad):\n",
    "    mom = copy.deepcopy(mom)\n",
    "    dad = copy.deepcopy(dad)\n",
    "    \n",
    "    \n",
    "    net = Network(mom.input_shape)\n",
    "    net.output_shape = mom.output_shape\n",
    "    net.layers.append(mom.layers[0])\n",
    "\n",
    "    for layer_one in mom.layers[1:]:\n",
    "        for layer_two in dad.layers[1:]:\n",
    "            if layer_one.id == layer_two.id:\n",
    "                if np.random.choice([True, False], 1, p=[0.5, 0.5]):\n",
    "                    net.layers.append(layer_one)\n",
    "                else:\n",
    "                    net.layers.append(layer_two)\n",
    "    \n",
    "    net.trim_shapes()\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1468,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = Layer(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Network: Layers= \n",
      "[Layer: [shape=(10, 20)], Layer: [shape=(20, 30)], Layer: [shape=(30, 10)], Layer: [shape=(10, 10)]]\n",
      "[Layer: [shape=(10, 21)], Layer: [shape=(21, 32)], Layer: [shape=(32, 10)], Layer: [shape=(10, 10)]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "net = Network(10)\n",
    "net.add_layer(20,passthrough=False)\n",
    "#net.add_layer(100, passthrough=False)\n",
    "net.add_layer(30, passthrough=False)\n",
    "net.add_layer(10, passthrough=False)\n",
    "net.add_layer(10, passthrough=False, locked=True)\n",
    "print(net.predict(np.zeros(10)))\n",
    "\n",
    "print(net)\n",
    "net.mutate_link()\n",
    "net.mutate_link()\n",
    "net.mutate_link()\n",
    "net.mutate_link()\n",
    "net.mutate_node()\n",
    "net.mutate_node()\n",
    "net.mutate_node()\n",
    "net.mutate_node()\n",
    "\n",
    "net.mutate(0.1, 0.1)\n",
    "print(net.layers)\n",
    "print(net.predict(np.zeros(10)))\n",
    "\n",
    "\n",
    "#net.print_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1487,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkPool():\n",
    "    def __init__(self, input_shape, output_shape, population_size=100):\n",
    "        self.networks = []\n",
    "        for _ in range(population_size):\n",
    "            \n",
    "            net = Network(input_shape=input_shape)\n",
    "            net.add_layer(1, passthrough=True)\n",
    "            #net.add_layer(128, passthrough=False)\n",
    "            net.add_layer(output_shape, passthrough=True, locked=True)\n",
    "            \n",
    "            self.networks.append(net)            \n",
    "\n",
    "    \n",
    "    def fit(self, data, epochs=100, num_survivors=10, num_children=10, batch_size=32, loss=tf.keras.losses.MeanSquaredError()):\n",
    "        X, y = data\n",
    "        \n",
    "        batch_start = 0\n",
    "        \n",
    "        t = trange(epochs, desc='Loss', leave=True)\n",
    "        for _ in t:            \n",
    "            batch_X = np.array(X[batch_start:np.min([batch_start+batch_size, len(X)])]).astype(np.float)\n",
    "            batch_y = np.array(y[batch_start:np.min([batch_start+batch_size, len(y)])]).astype(np.float)\n",
    "            \n",
    "            batch_start = (batch_start + batch_size) % len(X)\n",
    "            \n",
    "            losses = []\n",
    "            for network in self.networks:    \n",
    "                prediction = network.predict(batch_X).astype(np.float)\n",
    "                losses.append(loss(batch_y, prediction))\n",
    "                \n",
    "            losses = np.array(losses)\n",
    "            \n",
    "            #losses = np.mean(losses, axis=1)#.reshape(len(self.networks), -1).astype('float32')\n",
    "\n",
    "            t.set_description(\"Population: loss_min={:.4f}, loss_avg={:.4f}\".format(np.min(losses), np.mean(losses)))\n",
    "\n",
    "            idx = np.argsort(losses)\n",
    "\n",
    "            survivors = [self.networks[x] for x in idx[:num_survivors]] #self.networks[idx[:num_survivors]]\n",
    "            \n",
    "            \n",
    "            self.best_network = self.networks[idx[0]]\n",
    "            \n",
    "            \n",
    "            # Mutate all surviors and use them as the new networks\n",
    "            # The best network survives\n",
    "            self.networks = [self.best_network]\n",
    "            for survivor1 in survivors:\n",
    "                for survivor2 in survivors:\n",
    "                    for _ in range(num_children):\n",
    "                        child = crossbreed(survivor1,survivor2)\n",
    "                        child.mutate(p_link=0.2, p_node=0.2, p_mutate=0.7)\n",
    "                        self.networks.append(child)\n",
    "            \n",
    "            for survivor in survivors:\n",
    "                if survivor.age < 5:\n",
    "                    survivor.age += 1\n",
    "                    survivor.mutate(p_link=1, p_node=0, p_mutate=1)\n",
    "                    self.networks.append(survivor)\n",
    "            \n",
    "            #print(\"____________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1488,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "y = np.array([[0.], [1.], [1.], [0.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1489,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Population: loss_min=0.0000, loss_avg=0.0558: 100%|██████████| 100/100 [00:15<00:00,  6.27it/s]\n"
     ]
    }
   ],
   "source": [
    "pool = NetworkPool(input_shape=2, output_shape=1, population_size=1)\n",
    "pool.fit((X,y), epochs=100, num_survivors=5, num_children=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.99900067],\n",
       "       [0.99797647],\n",
       "       [0.        ]])"
      ]
     },
     "execution_count": 1490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool.best_network.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Layer: [shape=(2, 13)],\n",
       " Layer: [shape=(13, 16)],\n",
       " Layer: [shape=(16, 19)],\n",
       " Layer: [shape=(19, 24)],\n",
       " Layer: [shape=(24, 1)],\n",
       " Layer: [shape=(1, 1)]]"
      ]
     },
     "execution_count": 1491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool.best_network.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1492,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "mnist = tensorflow.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1493,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(-1, 28*28)\n",
    "x_test = x_test.reshape(-1, 28*28)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test =scaler.transform(x_test)\n",
    "\n",
    "\n",
    "y_train_onehot = np.zeros((y_train.size, y_train.max()+1))\n",
    "y_train_onehot[np.arange(y_train.size),y_train] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool = NetworkPool(input_shape=784,output_shape=10, population_size=1)\n",
    "len(pool.networks[0].layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1495,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Population: loss_min=0.0923, loss_avg=0.0942: 100%|██████████| 400/400 [01:28<00:00,  4.53it/s]\n"
     ]
    }
   ],
   "source": [
    "loss=tf.keras.losses.CategoricalCrossentropy()\n",
    "pool.fit((x_train,y_train_onehot), epochs=400, batch_size=100, num_survivors=5, num_children=4)#, loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.63481105, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 1496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool.best_network.layers[-1].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5, 4, 0, 7, 4, 0, 1, 3, 1, 3, 4, 7]\n"
     ]
    }
   ],
   "source": [
    "index = [2547,19910,12233,54220]\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "#print(pool.best_network.predict([x_train[index]]))\n",
    "print(np.argmax(pool.best_network.predict(x_test), axis=1).tolist()[:35])\n",
    "print(y_test.tolist()[:35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
