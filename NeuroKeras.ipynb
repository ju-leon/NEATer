{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import trange\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1303,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer():\n",
    "    def __init__(self, output_shape, input_shape, activation=\"relu\"):\n",
    "        w_init = tf.keras.initializers.Orthogonal()\n",
    "        self.weights = tf.Variable(\n",
    "            initial_value=w_init(shape=(input_shape, output_shape), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.weights = self.weights + np.random.normal(size=(input_shape, output_shape), scale=0.1)\n",
    "\n",
    "        b_init = tf.keras.initializers.Zeros()\n",
    "        self.biases = tf.Variable(\n",
    "            initial_value=b_init(shape=(output_shape,), dtype=\"float32\"), trainable=True\n",
    "        )\n",
    "\n",
    "        self.output_shape = output_shape\n",
    "        self.input_shape = input_shape\n",
    "        self.size = self.weights.shape\n",
    "        \n",
    "        if activation == \"relu\":\n",
    "            self.activation = tf.keras.activations.relu\n",
    "        if activation == \"tanh\":\n",
    "            self.activation = tf.keras.activations.tanh\n",
    "        \n",
    "    def add_weights(self, weights):\n",
    "        self.weights = self.weights + weights\n",
    "        \n",
    "    def add_biases(self, biases):\n",
    "        self.biases = self.biases + biases\n",
    "    \n",
    "    def extend(self):\n",
    "        self.weights = np.append(self.weights, np.random.normal(size=(self.input_shape,1)), axis=1)\n",
    "        self.biases = np.append(self.biases, 0)        \n",
    "        self.output_shape += 1\n",
    "        self.size = self.weights.shape\n",
    "    \n",
    "    def extend_input(self):\n",
    "        self.weights = np.append(self.weights, np.random.normal(size=(1,self.output_shape)), axis=0)\n",
    "        self.input_shape += 1\n",
    "        self.size = self.weights.shape\n",
    "        \n",
    "    def decrease(self):\n",
    "        self.weights = np.delete(self.weights, -1, axis=0)\n",
    "        self.biases = np.delete(self.biases, -1)        \n",
    "        self.output_shape -= 1\n",
    "        self.size = self.weights.shape\n",
    "    \n",
    "    def decrease_input(self):\n",
    "        self.weights = np.delete(self.weights, -1, axis=1)\n",
    "        self.input_shape -= 1\n",
    "        self.size = self.weights.shape\n",
    "    \n",
    "    def change_output_size(self, size):\n",
    "        while self.output_shape != size:\n",
    "            if self.output_shape > size:\n",
    "                self.decrease()\n",
    "            elif self.output_size < size:\n",
    "                self.extend()\n",
    "                \n",
    "    def call(self, inputs):\n",
    "        return self.activation(tf.matmul(inputs, self.weights) + self.biases)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"Layer: [shape=\" + str(self.weights.shape) + \"]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1304,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network():\n",
    "    def __init__(self, input_shape):\n",
    "        self.layers = []\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "    def add_layer(self, size, activation=relu, weights=None, biases=None):\n",
    "        if len(self.layers) == 0:\n",
    "            self.layers.append(\n",
    "                Layer(\n",
    "                    size,\n",
    "                    self.input_shape,  \n",
    "                    #activation=activation, \n",
    "                    #weights=weights, \n",
    "                    #biases=biases\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            self.layers.append(\n",
    "                Layer(\n",
    "                    size, \n",
    "                    self.layers[-1].output_shape, \n",
    "                    #activation=activation,\n",
    "                    #weights=weights, \n",
    "                    #biases=biases\n",
    "                )\n",
    "            )\n",
    "            \n",
    "    def predict(self, sample):\n",
    "        result = sample\n",
    "        for layer in self.layers:\n",
    "            result = layer.call(result)\n",
    "        return np.array(result)\n",
    "    \n",
    "    \n",
    "    def mutate_weights(self, intensity=0.1):\n",
    "        for layer in self.layers:\n",
    "            layer.add_weights(np.random.normal(scale=intensity, size=layer.size))\n",
    "            layer.add_biases(np.random.normal(scale=intensity, size=layer.output_shape))\n",
    "            \n",
    "    def mutate_layers(self, propa=0.1):\n",
    "        for i in range(len(self.layers)-1):\n",
    "            if np.random.choice([True, False], p=[propa,1-propa]):\n",
    "                self.layers[i].extend()\n",
    "                self.layers[i+1].extend_input()\n",
    "            #elif np.random.choice([True, False], p=[propa,1-propa]):\n",
    "            #    if self.layers[i].output_shape > 3:\n",
    "            #        self.layers[i].decrease()\n",
    "            #        self.layers[i+1].decrease_input()\n",
    "        \n",
    "    def mutate_topology(self, propa=0.1, activation=\"tanh\"):\n",
    "        choice = np.random.choice([0, 1], p=[propa,1-propa])\n",
    "        # Add a Layer\n",
    "        if choice == 0:\n",
    "            if len(self.layers) == 1:\n",
    "                index = 1\n",
    "                layer = Layer(input_shape=self.layers[0].output_shape, output_shape=self.layers[0].output_shape, activation=activation)\n",
    "            else:\n",
    "                index = np.random.randint(1, len(self.layers))\n",
    "                layer = Layer(input_shape=self.layers[index-1].output_shape, output_shape=self.layers[index].input_shape, activation=activation)\n",
    "\n",
    "            self.layers.insert(index, layer)\n",
    "        # Remove a layer\n",
    "        #elif choice == 1:\n",
    "        #    if len(self.layers) > 2:\n",
    "        #        index = np.random.randint(1, len(self.layers) - 1)\n",
    "        #        self.layers[index-1].change_output_size(self.layers[index+1].input_size)\n",
    "        #        del self.layers[index]\n",
    "            \n",
    "            \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"Network: Layers= \\n\" + str(self.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network: Layers= \n",
      "[Layer: [shape=(2, 5)], Layer: [shape=(5, 8)], Layer: [shape=(8, 8)], Layer: [shape=(8, 7)], Layer: [shape=(7, 3)], Layer: [shape=(3, 3)]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.15864423, 0.        , 0.09909432],\n",
       "       [0.15864423, 0.        , 0.09909432],\n",
       "       [0.15864423, 0.        , 0.09909432],\n",
       "       [0.15864423, 0.        , 0.09909432],\n",
       "       [0.15864423, 0.        , 0.09909432],\n",
       "       [0.15864423, 0.        , 0.09909432],\n",
       "       [0.15864423, 0.        , 0.09909432],\n",
       "       [0.15864423, 0.        , 0.09909432]], dtype=float32)"
      ]
     },
     "execution_count": 1305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Network(input_shape=2)\n",
    "net.add_layer(4)\n",
    "\n",
    "net.add_layer(7)\n",
    "net.add_layer(6)\n",
    "net.add_layer(2)\n",
    "net.add_layer(3)\n",
    "\n",
    "\n",
    "#net.mutate_layers(propa=0.1)\n",
    "net.mutate_topology(propa=1)\n",
    "net.mutate_layers(propa=1)\n",
    "\n",
    "print(net)\n",
    "net.predict(np.ones((8,2)).astype(np.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1306,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "class NetworkPool():\n",
    "    def __init__(self, input_shape, output_shape, population_size=100):\n",
    "        self.networks = []\n",
    "        for _ in range(population_size):\n",
    "            \n",
    "            net = Network(input_shape=input_shape)\n",
    "            net.add_layer(output_shape, activation=\"tanh\")\n",
    "            \n",
    "            self.networks.append(net)            \n",
    "        #self.networks = np.array(self.networks)\n",
    "            \n",
    "    \n",
    "    def fit(self, data, epochs=100, num_survivors=10, num_children=10, batch_size=32, loss=tf.keras.losses.mean_squared_error):\n",
    "        X, y = data\n",
    "        \n",
    "        batch_start = 0\n",
    "        \n",
    "        t = trange(epochs, desc='Loss', leave=True)\n",
    "        for _ in t:            \n",
    "            batch_X = np.array(X[batch_start:np.min([batch_start+batch_size, len(X)])]).astype('float32')\n",
    "            batch_y = np.array(y[batch_start:np.min([batch_start+batch_size, len(y)])]).astype('float32')\n",
    "            \n",
    "            batch_start = (batch_start + batch_size) % len(X)\n",
    "            \n",
    "            predictions = []\n",
    "            for network in self.networks:\n",
    "                predictions.append(network.predict(batch_X))\n",
    "            \n",
    "            predictions = np.array(predictions)#.reshape(len(self.networks), -1).astype('float32')\n",
    "            #print(predictions)\n",
    "            \n",
    "            losses = tf.math.reduce_mean(loss(predictions, [batch_y]), axis=-1)\n",
    "\n",
    "            t.set_description(\"Population: loss_min={:.4f}, loss_avg={:.4f}\".format(np.min(losses), np.mean(losses)))\n",
    "\n",
    "            idx = np.argsort(losses)\n",
    "\n",
    "            survivors = [self.networks[x] for x in idx[:num_survivors]] #self.networks[idx[:num_survivors]]\n",
    "            \n",
    "            self.best_network = self.networks[idx[0]]\n",
    "            \n",
    "            \n",
    "            # Mutate all surviors and use them as the new networks\n",
    "            # The best network survives\n",
    "            self.networks = [self.best_network]\n",
    "            for survivor1 in survivors:\n",
    "                #for survivor2 in survivors:\n",
    "                for _ in range(num_children):\n",
    "                    #child = survivor1.crossbreed(survivor2, random_mutations=True)\n",
    "                    child = copy.deepcopy(survivor1)\n",
    "                    child.mutate_layers()\n",
    "                    child.mutate_topology()                    \n",
    "                    child.mutate_weights()\n",
    "                    self.networks.append(child)\n",
    "            \n",
    "            #self.networks = np.array(self.networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1307,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0,0], [0,1], [1,0], [1,1]]).astype(np.float32)\n",
    "y = np.array([[0.], [1.], [1.], [0.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1308,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Population: loss_min=0.0000, loss_avg=0.1067: 100%|██████████| 50/50 [00:03<00:00, 16.66it/s]\n"
     ]
    }
   ],
   "source": [
    "pool = NetworkPool(input_shape=2, output_shape=1, population_size=200)\n",
    "pool.fit((X,y), epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.6528554e-04]\n",
      " [ 9.9918944e-01]\n",
      " [ 9.9695343e-01]\n",
      " [-8.8779780e-04]]\n",
      "Network: Layers= \n",
      "[Layer: [shape=(2, 4)], Layer: [shape=(4, 1)]]\n"
     ]
    }
   ],
   "source": [
    "print(pool.best_network.predict(X))\n",
    "print(pool.best_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1310,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1311,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train = x_train.reshape(-1, 28*28)\n",
    "x_test = x_test.reshape(-1, 28*28)\n",
    "\n",
    "y_train_onehot = np.zeros((y_train.size, y_train.max()+1))\n",
    "y_train_onehot[np.arange(y_train.size),y_train] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1319,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = NetworkPool(input_shape=784,output_shape=10, population_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1320,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Population: loss_min=0.2432, loss_avg=0.4425:  43%|████▎     | 430/1000 [00:13<00:17, 31.95it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1320-cf51b77cb1ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_onehot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_survivors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_children\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1306-91d6c98a7081>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data, epochs, num_survivors, num_children, batch_size, loss)\u001b[0m\n\u001b[1;32m     53\u001b[0m                     \u001b[0;31m#child = survivor1.crossbreed(survivor2, random_mutations=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                     \u001b[0mchild\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msurvivor1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                     \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmutate_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m                     \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmutate_topology\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                     \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmutate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1304-58f8ab6e06ab>\u001b[0m in \u001b[0;36mmutate_layers\u001b[0;34m(self, propa)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmutate_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpropa\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpropa\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpropa\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pool.fit((x_train,y_train_onehot), epochs=1000, batch_size=10, num_survivors=4, num_children=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network: Layers= \n",
       "[Layer: [shape=(784, 10)], Layer: [shape=(10, 10)], Layer: [shape=(10, 11)], Layer: [shape=(11, 10)], Layer: [shape=(10, 10)], Layer: [shape=(10, 10)]]"
      ]
     },
     "execution_count": 1316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool.best_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1317,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Network' object has no attribute 'predict_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1317-f2b12c8c550a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#print(pool.best_network.predict_all(x_train[index]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmae_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Network' object has no attribute 'predict_all'"
     ]
    }
   ],
   "source": [
    "index = [2547,19910,12233,54220]\n",
    "\n",
    "#print(pool.best_network.predict_all(x_train[index]))\n",
    "print(np.argmax(pool.best_network.predict_all(x_test), axis=1))\n",
    "print(y_test)\n",
    "#print(mae_loss(np.argmax(pool.best_network.predict_all(x_test), axis=1), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float64, numpy=\n",
       "array([[4., 4.],\n",
       "       [4., 4.]])>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(np.ones((2,4)), np.ones((4,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1 256   9]\n"
     ]
    }
   ],
   "source": [
    "print(tf.keras.losses.mean_squared_error([[1],[23],[3]], [[2],[7],[6]]).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
